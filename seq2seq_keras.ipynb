{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq - Keras - Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: [CMU Dict](http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b)\n",
    "An introductory Seq2Seq model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras, keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "Path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Code to cap GPU memory usage\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parms = {'verbose': 0, 'callbacks': [TQDMNotebookCallback(leave_inner=True)]}\n",
    "lstm_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A', ['AH0'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get each word that begins with A-Z from each line into a list \n",
    "lines = [l.strip().split(\"  \") for l in open(Path+'cmudict-0.7b', encoding='latin1') \n",
    "         if re.match('^[A-Z]', l)]\n",
    "#Split words and phonemes\n",
    "lines = [(w, ps.split()) for w, ps in lines]\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a list of all the unique phonemes from lines and adding _ to position 0 because it corresponds to padding\n",
    "#when tokenised\n",
    "phonemes = [\"_\"]+sorted(set(p for w, ps in lines for p in ps))\n",
    "len(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Map phonemes to indices and letters to indices.\n",
    "p2i = dict((v, k) for k, v in enumerate(phonemes))\n",
    "letters = \"_abcdefghijklmnopqrstuvwxyz*\"\n",
    "l2i = dict((v, k) for k, v in enumerate(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 15\n",
    "#Map words to corresponding list of phoneme indices. Constraint\n",
    "pronounce_dict = {w.lower(): [p2i[p] for p in ps] for w, ps in lines\n",
    "                    if (5<=len(w)<=maxlen) and re.match(\"^[A-Z]+$\", w)}\n",
    "len(pronounce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_p = max([len(v) for k,v in pronounce_dict.items()]); maxlen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#words contain the number of words in the filtered dictionary\n",
    "words = np.random.permutation(list(pronounce_dict.keys()))\n",
    "n = len(words)\n",
    "\n",
    "#Initialise the input and labels array with zeros so that everywhere except \n",
    "#the position of values is padded\n",
    "input_ = np.zeros((n, maxlen_p), np.int32)\n",
    "labels_ = np.zeros((n, maxlen), np.int32)\n",
    "\n",
    "#Fill in the non zero indices\n",
    "for i, k in enumerate(words):\n",
    "    for j, p in enumerate(pronounce_dict[k]): input_[i][j]=p\n",
    "    for j, p in enumerate(k): labels_[i][j] = l2i[p]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create train, validation sets\n",
    "(input_train, input_test, labels_train, labels_test) = train_test_split(input_, labels_, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size, output_vocab_size = len(phonemes), len(letters);input_vocab_size, output_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rnn(return_sequences=True):\n",
    "    return LSTM(dim, dropout=0.1, recurrent_dropout=0.1, \n",
    "                implementation=2, return_sequences=return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input after embedding becomes #sample*maxlen_p*120\n",
    "inp = Input((maxlen_p,))\n",
    "x = Embedding(input_vocab_size, 120)(inp)\n",
    "\n",
    "#Encoding stage - form a representation of all the information in the word as a whole\n",
    "#Bidirectional creates a separate RNN for a reverse input which is then concat \n",
    "#with original RNN.\n",
    "x = Bidirectional(get_rnn())(x)\n",
    "x = get_rnn(False)(x)\n",
    "\n",
    "#Decoding stage\n",
    "#RepeatVector is used because RNN in Keras expect a list of inputs rather than a \n",
    "#a single hidden state representation. Another issue is that it is also harder for the RNN to keep\n",
    "#track of what the whole word that needs to be decoded. By repeating, each timestep is preented\n",
    "#with the same vector. \n",
    "x = RepeatVector(maxlen)(x)\n",
    "x = get_rnn()(x)\n",
    "x = get_rnn()(x)\n",
    "x = TimeDistributed(Dense(output_vocab_size, activation='softmax'))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 16, 120)           8400      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 16, 480)           693120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 240)               692160    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 15, 240)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 15, 240)           461760    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15, 240)           461760    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 15, 28)            6748      \n",
      "=================================================================\n",
      "Total params: 2,323,948\n",
      "Trainable params: 2,323,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(input_train, np.expand_dims(labels_train, -1),\n",
    "                validation_data=[input_test, np.expand_dims(labels_test, -1)],\n",
    "                batch_size=128, **parms, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights('models/seq2seq_rnn.h5')\n",
    "model.load_weights('models/seq2seq_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(input_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = np.argmax(preds, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.29932413665401353\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy', np.mean([all(real==p) for real, p in zip(labels_test, predict)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(predict):\n",
    "    print ('Phonemes_________________________________predictions______label')\n",
    "    for index in range(20):\n",
    "        phoneme = '-'.join([phonemes[p] for p in input_test[index]])\n",
    "        prediction = [letters[l] for l in predict[index]]\n",
    "        real = [letters[l] for l in labels_test[index]]\n",
    "        print (phoneme.strip('-_').ljust(40), ''.join(prediction).strip('_').ljust(14), \n",
    "               ''.join(real).strip('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phonemes_________________________________predictions______label\n",
      "P-EH0-K-AO1-R-AH0                        pecora         pecora\n",
      "N-AH1-JH-IH0-NG                          nudging        nudging\n",
      "HH-AO1-R-W-IH0-T-S                       horwitz        horwitz\n",
      "K-Y-UW1-K-ER0                            kuker          kuker\n",
      "L-IH1-V-R-IY0-D                          livride        liveried\n",
      "D-IH0-V-IY1-T-AH0                        divita         devita\n",
      "W-IY1-V-AH0-L                            weevll         weavil\n",
      "F-L-AH1-K-CH-AH0-W-EY2-T-IH0-D           fluctuated     fluctuated\n",
      "B-IH1-S-IH0-T                            bisset         bissett\n",
      "S-W-EH1-T-S-UW2-T                        swettsut       sweatsuit\n",
      "K-R-AY1-T-S                              crites         crites\n",
      "F-EH1-N-D-R-IH0-K                        fendrick       fendrick\n",
      "B-EY1-ER0                                bayer          bayar\n",
      "T-OW2-T-AE2-L-AH0-T-EH1-R-IY0-AH0-N-IH2-Z-AH0-M totilatatiiism totalitarianism\n",
      "T-R-UW1-AH0-N-T                          trueat         truant\n",
      "F-L-OW1-D-IH0-N                          flodinn        flodin\n",
      "HH-IH1-CH-M-AH0-N                        hichman        hitchman\n",
      "M-AH1-N-S-IY0                            munci          muncy\n",
      "F-L-UW1-AH0-N-S-IY0                      fluwncyy       fluency\n",
      "Z-OW0-AA1-L-AH0-JH-AH0-S-T-S             zoallgists     zoologists\n"
     ]
    }
   ],
   "source": [
    "evaluate(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
